\chapter{Experimentelle Untersuchungen}
\chaptermark{Exp. Untersuchungen}

Um die Wirksamkeit der Parallelisierung der N++-Bibliothek in C++ zu bewerten, wird ein umfassender Benchmark-Test durchgeführt. Dieser Test umfasst verschiedene Kombinationen von Threads, Anzahl an Datensätzen und verschiedenen Computern mit verschiedenen Prozessorarchitekturen, um die Auswirkungen der Implementierung auf die Leistung der Bibliothek unter unterschiedlichen Bedingungen zu untersuchen.

\section{Testumgebung}

Das C++ Programm wurde unter Einbindung der N++-Bibliothek auf dem jeweiligen System selbst kompiliert. Dabei wurde die Optimierungsstufe O2 verwendet, welche eine für Produktionssoftware gängige Optimierungsstufe ist. Die O2 Optimierungsstufe wendet fast jede Compileroptimierung an, die die Compiler zu bieten haben. Dabei werden lediglich als sehr unsicher eingestufte Optimierungen ausgelassen. Auf Linux wurde der GCC Compiler (Version 12.2.0-14) und auf MacOS der Clang Compiler (Version 1500.3.9.4) verwendet, um native Binärdateien für die spezifische Prozessorarchitektur zu kompilieren. Das heißt, das Programm wurde nicht unter Emulation sondern vollständig nativ ausgeführt.

Die Tests wird mit unterschiedlichen Thread-Anzahlen ausgeführt, darunter 10, 8, 6, 4 und 2 gleichzeitig laufenden Threads, um den Einfluss der Parallelisierung auf die Ausführungsgeschwindigkeit zu untersuchen. Zusätzlich wird das Programm auch mit einem einzelnen Thread ausgeführt, um einen Vergleich mit der vorausgegangenen Implementierung herstellen zu können. Für jede Thread-Anzahl werden außerdem verschiedene Größen an Datensätzen getestet. Die Größe der Datensätze wird über die Anzahl an Partitionen spezifiziert. Eine Partition bedeutet dabei, dass die gesamte Datenmenge verwendet wird, wohingegen 4 Partitionen bedeuten, dass nur ein Viertel, also 25\% der Datenmenge verwendet werden. Das Programm wird in diesem Test mit 1, 2, 4 und 8 Partitionen getestet, wobei es auf dem langsamsten Computer nur auf 4 und 8 beschränkt wurde.

Für jede Kombination von Threads und Partitionen werden mindestens 5 Testläufe durchgeführt, um robuste Durchschnittswerte zu erhalten und Schwankungen zu minimieren. Gemessen wird die benötigte Zeit für den gesamten Programmdurchlauf in Sekunden. Vor jedem Durchlauf werden die Testgeräte auf einen neutralen Zustand zurückgesetzt, um faire Vergleichsbedingungen sicherzustellen. Dies wird gewährleistet, indem gleiche Seeds für die Zufallszahlgeneratoren verwendet werden, und sichergestellt wird, dass keine anderen Programme laufen.
Das Ergebnis jedes Programmdurchlaufs wird in eine Datei geschrieben, um vergleichen zu können, ob mit verschiedenen Anzahlen von Threads die gleichen Ergebnisse berechnet werden.

Nach Abschluss der Testläufe werden die erzielten Ergebnisse automatisch analysiert und Durchschnittswerte für jede Kombination von Threads und Partitionen berechnet. Diese Durchschnittswerte dienen dazu, die möglichen Schwankungen der Testabläufe auszugleichen, und ein neutraleres Ergebnis zu liefern.

\section{Getestete Hardware}
\label{sec:tested_hardware}
\sectionmark{Hardware}

Als erstes Testsysten kommt ein MacBook Pro 16 Zoll Laptop mit dem M1 Pro Prozessor, der im MacBook Pro 16 Zoll verwendet wird zum Einsatz. Der M1 Pro wurde 2021 vorgestellt und ist eine hochskalierte Version des M1 Prozessors. Er verfügt über insgesamt 12 CPU-Kerne, darunter 8 Hochleistungs- und 4 Effizienzkerne \citep{MacBook_Technische_Daten}. Die Hochleistungskerne sind für rechenintensive Aufgaben konzipiert, während die Effizienzkerne für weniger anspruchsvolle Aufgaben und eine Reduzierung des Energieverbrauchs optimiert sind.
In Bezug auf die Leistung bietet der M1 Pro Prozessor eine sehr beeindruckende Single-Core-Leistung und ist das performanteste der getesteten Systeme. Die Hauptspeichergröße beträgt 16 GB, welche mit einer Speicherbandbreite von 200 GBit/s \citep{MacBook_Technische_Daten} angebunden sind. Auch die Cache-Größe des Prozessors ist sehr hoch, was die Latenz bei Speicherzugriffen zusätzlich vermindern kann.
Verwendet wurde MacOS Sonoma 14.5 mit dem Darwin Kernel Version 23.5.0 und Clang Version 1500.3.9.4.

Als Desktopprozessor wurde der AMD Ryzen 5 3600XT getestet, welcher ein Prozessor aus der Ryzen 3000-Serie von AMD ist, der im Jahr 2020 eingeführt wurde. Er verfügt über insgesamt 6 CPU-Kerne und 12 Threads auf Basis der Zen 2-Architektur, welche auch im Servermarkt verbreitet ist. Es handelt sich um einen Desktopprozessor mit einer maximalen Leistungsaufnahme von 95 Watt \citep{Ryzen_Technische_Daten}.
Der Prozessor unterstützt DDR4-RAM mit unübertakteten Geschwindigkeiten von bis zu 3200 MHz \citep{Ryzen_Technische_Daten}. Die genaue Speicherbandbreite und Größe hängt von der verwendeten RAM-Konfiguration ab, da Desktop Prozessoren modular in verschiedene Systeme eingebaut werden können.
In Bezug auf den Cache verfügt der Ryzen 5 3600XT über 32KB L1-Cache, 512KB L2-Cache und 32MB L3-Cache \citep{Ryzen_Technische_Daten}. In der Konfiguration des Testcomputers sind 16GB DDR4 Speicher mit 3600 MHz verbaut, und der Prozessor wird mit einer Wasserkühlung gekühlt, was für eine gleichmäßige und robuste Kühlung sorgt. Als Betriebssystem kam Fedora 40 mit dem Linux Kernel der Version 6.8 zum Einsatz.

Um auch ein System mit begrenzter Leistung zu testen wurde die Implementierung auch auf einem  Raspberry Pi 3 getestet, welcher ein Single-Board-Computer ist, der von der Raspberry Pi Foundation entwickelt wurde. Ein Single-Board-Computer ist eine vollständige Computerplatine, die alle erforderlichen Komponenten wie Prozessor, Speicher, Ein- und Ausgabeanschlüsse und Stromversorgung auf einer einzigen Platine vereint. Der Raspberry Pi 3 wurde 2016 veröffentlicht und basiert auf einem ARM Cortex-A53 Quad-Core-Prozessor mit einer Taktfrequenz von 1,2 GHz und 1 GB LPDDR2-RAM \citep{RaspberryPi_Technische_Daten}.
Der Raspberry Pi 3 ist aufgrund seiner geringen Größe, seines geringen Stromverbrauchs und seiner vielfältigen Einsatzmöglichkeiten beliebt. Er wird häufig in Bildungsprojekten, Hobbyprojekten, Heimautomatisierungssystemen und als kostengünstige Entwicklungsumgebung für Softwareentwickler eingesetzt. Trotz seiner begrenzten Leistungsfähigkeit erfüllt der Raspberry Pi 3 wichtige Funktionen in verschiedenen Anwendungsbereichen aufgrund seiner Kompaktheit und seines erschwinglichen Preises.
Aufgrund der begrenzten Leistung und der damit verbundenen Laufzeiten konnte der Testablauf nicht vollständig durchgeführt werden. Es wurden maximal 4 Threads getestet, und die Partitionen wurden auf 8 und 4 begrenzt. Die Linux Kernel Version 6.6 kam auf Raspberry Pi OS Lite 12 in der 64-Bit Version zum Einsatz.

Um die Skalierbarkeit und das Verhalten der Algorithmen in unterschiedlichsten Umgebungen zu beleuchten, wurden die Benchmarks zusätzlich auf einem VPS-Server des Anbieters Contabo durchgeführt. Diese Wahl bot gleich zweifache Vorteile: Zum einen ermöglichte sie die Evaluierung der Algorithmenleistung in einer Cloud-Umgebung, die in der heutigen Anwendungslandschaft immer relevanter wird, zum anderen bietet sie einen modernen performanten Prozessor, welche jedoch aufgrund der Virtualisierung auf 2 Kerne beschränkt ist.
Der Server verfügt über einen AMD EPYC 7282 Prozessor, der speziell für rechenintensive Aufgaben in Serverumgebungen entwickelt wurde. Mit seinen 16 Kernen und 32 Threads bietet er eine beachtliche Rechenleistung. Der Basistakt liegt bei 2,8 GHz und der Cache ist 64 MB groß \citep{Epyc_Specifications}.
Von diesem leistungsstarken Prozessor stehen dem VPS-Server lediglich 2 Kerne und 4 GB Arbeitsspeicher zur Verfügung. Diese Einschränkung sollte Aufschluss darüber geben, wie effizient die Algorithmen mit limitierten Ressourcen umgehen können und wie sie in skalierbaren Umgebungen performen. Der verwendete Linux-Kernel war die Version 6.1.0-21 auf Debian 12.

\section{Benchmark Script}

Aus 6 verschiedenen Anzahlen an Threads, 4 verschiedenen Größen der Datensätze und 5 Durchläufen pro Kombination ergeben sich 120 einzelne Tests, die pro System ausgeführt werden müssen.
Um diese Arbeit zu erleichtern und einen reproduzierbaren Testprozess zu ermöglichen wurde ein Skript geschrieben, welches alle Tests nacheinander automatisch ausführt.

Das Skript misst die benötigten Laufzeiten der Durchläufe und schreibt nach jedem Durchlauf die benötigte Zeit in eine Datei. Zusätzlich werden die Zeit und Informationen zu jedem Durchlauf auch in eine CSV-Datei geschrieben, um das Auswerten der Benchmarks auf einem System durch nur eine einzige Datei zu ermöglichen.

Als Parameter ist es möglich, die maximale Anzahl an Threads festzulegen. So ist es beispielsweise auf einem Raspberry Pi sinnvoll, das Programm nur mit maximal 4 Threads zu testen, da er nur über 4 Kerne verfügt.

Das Skript ist simpel und wurde in Bash geschrieben, was die Portabilität zwischen Linux und MacOS gewährleistet. Dabei wurde jedoch das Programm bc verwendet, welches auf den meisten Linux-Distributionen standardmäßig nicht vorinstalliert ist.

\begin{figure}[H]
\begin{minted}
[
frame=lines,
framesep=2mm,
baselinestretch=1.2,
fontsize=\footnotesize,
linenos
]{bash}
#!/bin/bash
ATTEMPTS=5
PARTITIONS=(8 4 2 1) # Verschiedene Partitionen zum Testen
THREADS=(10 8 6 4 2 1) # Verschiedene Thread Anzahlen zum Testen
AVAILABLE_THREADS=10 # Maximal verfügbare Anzahl an Threads für aktuelles System

function run_attempt {
    # Hier wird ein Durchlauf durchgeführt und getestet
}

# Test für jede mögliche Kombination durchführen
for partition in ${PARTITIONS[@]};do
  for threads in ${THREADS[@]};do
      if ((threads <= AVAILABLE_THREADS));then
        for ((i = 1; i <= ATTEMPTS; i++)); do
          run_attempt "$threads" "$partition" "$i"
        done
      fi
    done
done
\end{minted}
\caption{Vereinfacht dargestelltes Benchmark Skript. Es testet die benötigte Laufzeit der Implementierung mit verschiedenen Thread-Anzahlen und Datensatzgrößen.}
\label{fig:benchmark_script_code}
\end{figure}

\section{Ergebnisse}
\label{sec:results}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{../results/plots/m1pro/comp_all_threads.pdf}
\caption{Leistungstest auf Apple M1 Pro: Einfluss von Thread-Anzahlen auf Laufzeit bei variierenden Datensatzgrößen, welche den Mittelwert von 5 Durchläufen darstellt. Die Standardabweichung der Laufzeit ist in Tabelle \ref{tab:performance_comparison} einzusehen.}
\label{fig:m1pro_benchmark_threads}
\end{figure}

Die Analyse der Benchmark-Ergebnisse auf dem M1 Pro-Prozessor aus Abbildung \ref{fig:m1pro_benchmark_threads} liefert wertvolle Einblicke in die Effektivität von Parallelisierung des Programms. Durch Tests mit 10, 8, 6, 4, 2 und 1 Threads konnte eine größtenteils lineare Skalierung der Leistung beobachtet werden, wobei 10 Threads annähernd eine zehnfache Beschleunigung im Vergleich zu einem einzelnen Thread erzielten. Dies ist besonders bemerkenswert, da nur 8 Hochleistungskerne zur Verfügung stehen, und die verbleibenden 2 Threads gezwungenermaßen auf Effizienzkernen laufen müssen.

Interessanterweise zeigt sich jedoch eine bemerkenswerte Konvergenz der Leistungskurven bei 6 und 8 Threads. Dies resultiert aus der Verteilung der parallelen Aufgaben auf die verfügbaren Threads, welche in den Abbildungen \ref{fig:runtime_timeline_6threads} und \ref{fig:runtime_timeline_8threads} schematisch dargestellt ist. Mit 6 Threads werden zunächst 6 Aufgaben bearbeitet, während 4 Aufgaben verbleiben. Die verbleibenden 4 Aufgaben erfordern ungefähr dieselbe Ausführungszeit wie die 2 zusätzlichen Aufgaben bei Verwendung von 8 Threads, was in den Abbildungen an der gleichen Breite der Durchläufe erkennbar ist. Diese Konvergenz erklärt die nahezu identischen Leistungskurven bei 6 und 8 Threads.
Bei 6 Threads könnten zwar insgesamt 6 Aufgaben bearbeitet werden, jedoch sind beim zweiten Durchlauf 2 Threads im Leerlauf, während die verbleibenden 4 Threads genutzt werden. Bei 8 Threads bleiben im zweiten Durchlauf sogar 6 Threads inaktiv. Diese Effizienzunterschiede führen zu einer vergleichbaren Ausführungszeit für die verbleibenden Aufgaben bei 6 und 8 Threads.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{../results/plots/timeline/timeline_plot_6threads.pdf}
  \caption{Verteilung der Aufgaben auf die verfügbaren Threads bei einem Programmablauf mit 6 Threads}
  \label{fig:runtime_timeline_6threads}
\end{figure}

\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{../results/plots/timeline/timeline_plot_8threads.pdf}
  \caption{Verteilung der Aufgaben auf die verfügbaren Threads bei einem Programmablauf mit 8 Threads}
  \label{fig:runtime_timeline_8threads}
\end{figure}

Da für den Analyseschritt im Programmablauf alle 10 Ergebnisse benötigt werden, ist es algorithmisch nicht möglich, die Analyse vor Abschluss aller 10 Durchläufe auszuführen, um die Kerne, die im Leerlauf sind, zu nutzen. Es kann sich also nur eine gleichmäßige und effiziente Nutzung der Threads ergeben, wenn eine ganzzahlige Fraktion der gesamten Aufgaben als Threads zur Verfügung stehen. Bei 10 Aufgaben bedeutet das, dass 10, 5, 2 und 1 Thread ohne signifikanten Leerlauf der Threads voll ausgenutzt werden können, wenn man die Analyse auslässt.

Die Standardabweichung der Ergebnisse des Apple M1 Pro, welche in Tabelle \ref{tab:performance_comparison} ablesbar ist, ist insgesamt ziemlich gering, was für eine zuverlässige Verteilung der Threads von dem Betriebssystem  auf die verschiedenen Kerne spricht. Zu beobachten ist, dass die Standardabweichung selbstverständlich bei Tests, welche mehr Zeit beanspruchen höher ist, aber auch, dass bei diesem System die Standardabweichung bei 4 Threads verhältnismäßig leicht höher erscheint. Dies könnte eventuell an dem Scheduler des Kernels liegen, welcher dynamisch entscheidet, auf welchen Kernen Aufgaben laufen sollen. Ein weiterer Faktor könnte die heterogene Architektur mit den Hochleistungs- und Effizienzkernen sein.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{../results/plots/3600xt/comp_all_threads.pdf}
\caption{Leistungstest auf AMD Ryzen 5 3600XT: Einfluss von Thread-Anzahlen auf Laufzeit bei variierenden Datensatzgrößen, welche den Mittelwert von 5 Durchläufen darstellt. Die Standardabweichung der Laufzeit ist in Tabelle \ref{tab:performance_comparison} einzusehen.}
\label{fig:ryzen_benchmark_threads}
\end{figure}

Die angesprochenen Beobachtungen bestätigen sich beim zweiten Testsystem, dem AMD Ryzen 5 3600XT weitgehend bestätigen. Genau wie beim Apple M1 Pro lässt sich eine erfolgreiche Skalierung der Leistung bei höheren Thread-Zahlen feststellen, was in Abbildung \ref{fig:ryzen_benchmark_threads} veranschaulicht ist. Dieses System ist auch sehr leistungsstark, und kann von multithreaded Anwendungen stark profitieren. Insgesamt liegen die benötigten Laufzeiten circa 20\% über denen des Apple M1 Pro. Auch die zuvor erwähnte Konvergenz bei 6 und 8 verwendeten Threads ist zu erkennen. 

Besonders zu beobachten ist, dass der Leistungssprung der Laufzeiten von 6 auf 10 Threads bei diesem System geringer ist als bei dem Apple M1 Pro. Dies ist zu erwarten, da der AMD Ryzen 5 3600XT nur über 6 Kerne verfügt, welche zwar mithilfe von Hyper-Threading 12 physische Threads verfügbar stellen \citep{Ryzen_Technische_Daten}, jedoch nicht mit der Leistung von 12 Prozessorkernen vergleichbar sind. Bei 10 Laufenden Threads müssen sich somit 4 der 6 vorhandenen Prozessorkerne mit 2 Aufgaben gleichzeitig beschäftigen.

Die Standardabweichung der Testergebnisse ist im Allgemeinen auf dem gleichen Niveau mit denen des vorherig angesprochenen Systems. Deutliche Unterschiede zwischen Linux und MacOS konnten nicht beobachtet werden und für das getestete Programm scheint es keine großen Unterschiede zwischen dem Linux-Kernel und dem Darwin-Kernel von MacOS zu geben.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{../results/plots/raspberrypi3/comp_all_threads.pdf}
\caption{Leistungstest auf Raspberry Pi 3: Einfluss von Thread-Anzahlen auf Verarbeitungszeit bei variierenden Datensatzgrößen}
\label{fig:raspi_benchmark_threads}
\end{figure}

Der Raspberry Pi stellt das langsamste getestete System dar. Wie bereits in Sektion \ref{sec:tested_hardware} erläutert und in Abbildung \ref{fig:raspi_benchmark_threads} konnten deshalb aufgrund der zeitlichen Begrenzung nicht alle Tests durchgeführt werden. Im Vergleich zum Apple M1 Pro benötigt der Raspberry Pi bei 2 Threads mit 4755 Datensätzen beispielsweise nahezu 26 mal länger. Es ist zu sehen, dass auch der Raspberry Pi von der Parallelisierung profitiert, was gerade bei einem so langsamen System absolut gesehen enorme Unterschiede macht. So verbessert sich die Laufzeit bei 4755 Datensätzen von 7436 Sekunden (02h 03m 56s) bei einem verwendeten Thread auf 2235 Sekunden (37m 15s) unter der Verwendung von 4 Threads, was bedeutet, dass 1 Stunde und 26 Minuten an Laufzeit eingespart werden können.

Im Gegensatz zu dem MacBook mit macOS und dem Ryzen-System mit Fedora Linux lief auf dem getesteten Raspberry Pi keine grafische Oberfläche, welche eventuell Resourcen während des Tests in Anspruch nehmen könnte. Wirklich in den Ergebnissen durch eine deutlich geringere Standardabweichung im Vergleich zur Laufzeit bemerkbar machte sich das jedoch nicht, weshalb davon auszugehen ist, dass das Testen auf einem System mit grafischer Oberfläche auf diesen Systemen keine signifikanten Leistungseinbußen bedeutet. Da aber sowohl die vorhandene als auch die überarbeitete Implementierung weniger als 100 Megabyte Hauptspeicher benötigen, und sichergestellt wurde, dass während des Tests keine anderen Programme im Hintergrund laufen, war auch mit keinen größen Problemen diesbezüglich zu rechnen.

\begin{figure}[htbp!]
  \centering
  \includegraphics[width=0.8\textwidth]{../results/plots/timeline/timeline_plot_4threads.pdf}
  \caption{Verteilung der Aufgaben auf die verfügbaren Threads bei einem Programmablauf mit 8 Threads}
  \label{fig:runtime_timeline_4threads}
\end{figure}

Die Verteilung der 10 neuronalen Netze auf die 4 vorhandenen Kerne bei einem Programmablauf mit 4 Threads ist in Abbildung \ref{fig:runtime_timeline_4threads} dargestellt. Für die ersten 8 Durchläufe können die 4 Kerne des Raspberry Pi voll ausgenutzt werden, während danach nur noch maximal 2 von dem Programm ausgelastet werden. Da das Programm auf dem Raspberry Pi nicht mit 6 und 8 Threads getestet wurde ist die zuvor angesprochene Konvergenz nicht ersichtlich.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{../results/plots/vps/comp_all_threads.pdf}
\caption{Leistungstest auf AMD EPYC 7282 mit 2 verfügbaren Kernen: Einfluss von Thread-Anzahlen auf Verarbeitungszeit bei variierenden Datensatzgrößen}
\label{fig:vps_benchmark_threads}
\end{figure}

Als letztes System wurde der virtuelle Server mit einem AMD EPYC 7282 Prozessor getestet. Es zeigt sich in Abbildung \ref{fig:vps_benchmark_threads}, dass er unter Verwendung eines Threads ungefähr halb so schnell wie der Apple M1 Pro ist. Dem virtuellen Server stehen nur 2 Kerne zur Verfügung, was sich deutlich in den Ergebnissen wiederspiegelt. In den Tests mit 2 Threads zeigten sich genau wie bei den anderen getesteten Systemen deutliche Leistungsverbesserungen. Daran ist erkennbar, dass das Programm auch in Serverumgebungen genau so von Parallelisierung profitiert, wie zum Beispiel der AMD Ryzen 5 3600XT. Dies ist zu erwarten, da der AMD EPYC Prozessor die gleiche Mikroarchitektur wie der AMD Ryzen Prozessor namens Zen 2 \citep{Epyc_Specifications} verwendet. Der Serverprozessor ist in diesem Fall eine hochskalierte Version des für Privatkunden handelsüblichen Ryzen Prozessors. Abgesehen von der Anzahl der vorhandenen Kerne unterscheidet sich der AMD Epyc Prozessor auch durch seine deutlich geringere Taktraten vom AMD Ryzen, welche es ermöglichen, mehr Kerne bei gleicher verfügbarer Kühlleistung zu verbauen. Server haben normalerweise deutlich mehr Kerne als Prozessoren für Privatanwender

Deutlich erkennbar ist, dass dieses System nicht von mehr als 2 Threads profitiert. Die Leistungskurven von 2, 4, 6, 8 und 10 Threads liegen nahezu exakt übereinander, da die beiden vorhandenen Kerne von 2 Threads bereits voll ausgelastet werden.

\mycomment{Beschriftung der Diagramme bei 1 Thread ist noch "1 Threads". Das sollte geändert werden.}

\section{Auswertung}

Die durchgeführten Benchmarks auf den verschiedenen Testsystemen demonstrieren eindeutig die Leistungsverbesserungen durch die Parallelisierung der Anwendung und der Änderungen in der n++-Bibliothek. In allen getesteten Konfigurationen zeigte sich eine signifikante Reduktion der Laufzeit bei der Nutzung von mehr als einem Thread, was die Effektivität der parallelisierten Implementierung unterstreicht. Bis auf die Ausnahme der gleichbleibenden Laufzeiten bei 6 und 8 Threads, wie bereits im vorigen Abschnitt \ref{sec:results} erwähnt, lässt sich eine effektive Reduktion der Laufzeiten bei der Verwendung von mehr Threads ablesen.

Die getesteten Systeme umfassten sowohl verschiedene Prozessorarchitekturen als auch Betriebssysteme, um die Generalisierbarkeit der Ergebnisse sicherzustellen. In jedem Szenario wurde ein konsistenter Leistungszuwachs verzeichnet, sobald mehrere Threads zur Ausführung der Berechnungen herangezogen wurden, wie unten in Tabelle \ref{tab:performance_comparison} ablesbar.

Zusammenfassend lässt sich festhalten, dass die parallelisierte Implementierung der Vorarbeit erfolgreich war und die gesetzten Ziele in Bezug auf die Laufzeitoptimierung erreicht wurden. Die durchgeführten Tests bestätigen die Annahme, dass die Nutzung von Multithreading in der Lage ist, die Performance signifikant zu verbessern, wodurch die Effizienz und Praktikabilität der Bibliothek für reale Anwendungen gesteigert wird.


\begin{table}[H]
\caption{Benchmark-Ergebnisse für alle getesteten Systeme. Die benötigte Laufzeit $t$ ist ein Mittelwert aus jeweils mindestens 5 Durchläufen. Die Standardabweichung dieser Durchläufe ist mit $\sigma$ gekennzeichnet.}
\label{tab:performance_comparison}
\begin{adjustbox}{max width=\textwidth}
\renewcommand{\arraystretch}{1.5}
\input{../results/results_table.tex}
\end{adjustbox}
\end{table}
